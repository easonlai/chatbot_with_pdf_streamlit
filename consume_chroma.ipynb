{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the baseline configuration of the OpenAI library for Azure OpenAI Service.\n",
    "OPENAI_API_KEY = \"PLEASE_ENTER_YOUR_OWNED_AOAI_SERVICE_KEY\"\n",
    "OPENAI_API_BASE = \"https://PLESAE_ENTER_YOUR_OWNED_AOAI_RESOURCE_NAME.openai.azure.com/\"\n",
    "OPENAI_DEPLOYMENT_NAME = \"PLEASE_ENTER_YOUR_OWNED_AOAI_GPT_MODEL_NAME\"\n",
    "OPENAI_MODEL_NAME = \"text-davinci-003\"\n",
    "OPENAI_EMBEDDING_DEPLOYMENT_NAME = \"PLEASE_ENTER_YOUR_OWNED_AOAI_EMBEDDING_MODEL_NAME\"\n",
    "OPENAI_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "OPENAI_API_VERSION = \"2023-05-15\"\n",
    "OPENAI_API_TYPE = \"azure\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "openai.api_base = OPENAI_API_BASE\n",
    "openai.api_version = OPENAI_API_VERSION\n",
    "openai.api_type = OPENAI_API_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to interact with Azure OpenAI Embedding Model.\n",
    "embeddings = OpenAIEmbeddings(deployment=OPENAI_EMBEDDING_DEPLOYMENT_NAME, \n",
    "                                openai_api_key=OPENAI_API_KEY, \n",
    "                                model=OPENAI_EMBEDDING_MODEL_NAME, \n",
    "                                openai_api_type=OPENAI_API_TYPE, \n",
    "                                chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Chroma vector store and function to generate embeddings.\n",
    "db = Chroma(persist_directory=\"./chroma_db/\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Building a superhero team - Get your teammates to read this\n",
      "\n",
      "Congratulations on finishing this book!\n",
      "\n",
      "In Chapter 2, we talked about how this book can help you become the superhero of your team.\n",
      "\n",
      "The only thing better than being a superhero is being part of a superhero team. I hope youâ€™ll give copies of this book to your friends and teammates and help create other superheroes!\n",
      "\n",
      "Page 118\n",
      "\n",
      "Machine Learning Yearning-Draft\n",
      "\n",
      "Andrew Ng\n"
     ]
    }
   ],
   "source": [
    "# Define the query to search and display the most relevant document content.\n",
    "inquiry = \"Who is the author of this book?\"\n",
    "docs = db.similarity_search(inquiry)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Question Answering chain using the embeddings and the similarity search.\n",
    "chain = load_qa_chain(AzureOpenAI(openai_api_key=OPENAI_API_KEY, \n",
    "                                  deployment_name=OPENAI_DEPLOYMENT_NAME, \n",
    "                                  model_name=OPENAI_MODEL_NAME,\n",
    "                                  openai_api_version=OPENAI_API_VERSION),\n",
    "                                  chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The author of this book is Andrew Ng.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform first sample of question answering.\n",
    "inquiry = \"Who is the author of this book?\"\n",
    "docs = db.similarity_search(inquiry)\n",
    "chain.run(input_documents=docs, question=inquiry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This book provides advice on how to set technical direction for a machine learning project. It covers topics such as how to read clues in machine learning problems, task simplicity, and how to persuade team members to adopt a particular direction. It also provides information about how to build a successful machine learning team by giving copies of this book to friends and teammates.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform second sample of question answering.\n",
    "inquiry = \"Please tell me the key summary of this book.\"\n",
    "docs = db.similarity_search(inquiry)\n",
    "chain.run(input_documents=docs, question=inquiry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
